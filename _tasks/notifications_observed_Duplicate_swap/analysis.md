## Findings on duplicate swap notifications

- **Notification flow**: Clients hit `POST /api/v1/notifications` in `rumble-app-node` (`workers/lib/server.js:151-199`), which forwards to the ork (`rumble-ork-wrk/workers/api.ork.wrk.js:152-223`). The ork resolves the recipient wallet/user and RPCs the data shard’s proc to send the push. The data shard proc actually sends the FCM multicast (`rumble-data-shard-wrk/workers/proc.shard.data.wrk.js:539-579` → `workers/lib/utils/notification.util.js`).
- **Token duplication is already guarded**: Device storage rejects duplicate FCM tokens for the same user (`rumble-data-shard-wrk/workers/api.shard.data.wrk.js:22-41`), and push delivery dedupes tokens with a `Set` before sending (`rumble-data-shard-wrk/workers/proc.shard.data.wrk.js:550-556`). If a user had a duplicated token, they’d see duplicates on every notification, not intermittently, so this is unlikely the cause.
- **Swap completion notifications are transfer-based**: There is no explicit “swap completed” type; the user sees completion via the generic `TOKEN_TRANSFER_COMPLETED` that fires when a wallet receives the swap output (`_walletTransferDetected` hooked at `rumble-data-shard-wrk/workers/proc.shard.data.wrk.js:63-106, 628`).
- **Non-idempotent transfer notification trigger (likely culprit)**: The data shard emits a `new-transfer` event for *every* transfer it processes, even when the DB write is merely an upsert of an already-seen transfer (`wdk-data-shard-wrk/workers/proc.shard.data.wrk.js:525-589` uses `save` with upsert and immediately `emit('new-transfer', …)` without checking whether the row was new). Rumble’s listener then sends `TOKEN_TRANSFER_COMPLETED` pushes each time. Any reprocessing of the same transfer (poller reruns, router/push replay, or indexer resync) will therefore re-send the push even though the transfer is unchanged.
- **Replay window is realistic**: In that same batch loop, the notification is queued *before* the DB transaction commits and before checkpoints are advanced. If a later error causes the batch to roll back (`catch` at `wdk-data-shard-wrk/workers/proc.shard.data.wrk.js:587-589`), the notifications have already been sent but the checkpoint is not, so the next run reprocesses the same transfers and sends a second push. Price lookups call an external HTTP API with no retry/timeout guard (`workers/lib/price.calculator.js`), so intermittent failures there can trigger this pattern.
- **No idempotency on manual swap events either**: The `/api/v1/notifications` path is stateless—there’s no request ID or dedupe key. Any upstream retry for `SWAP_STARTED` (or a backend double-send) will fan out twice because the ork/data-shard simply forwards the request.

**Conclusion:** The intermittent duplicates line up with the non-idempotent transfer notification hook: swap “completion” pushes are tied to transfers, and the data shard will send a push every time it replays that transfer (even on upsert/rollback), not just on first insert. Token duplication is already prevented and would manifest as consistent, not sporadic, duplication.
